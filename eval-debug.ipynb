{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "concrete-princeton",
   "metadata": {},
   "outputs": [],
   "source": [
    "import errno\n",
    "import pickle\n",
    "import importlib.util\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "from typing import Union, Tuple\n",
    "\n",
    "import imageio\n",
    "import numpy as np\n",
    "from fairmotion.ops import conversions\n",
    "from torch import nn\n",
    "\n",
    "from bullet_agent import SimAgent\n",
    "from real_time_runner import RTRunner\n",
    "from real_time_runner_minimal import RTRunnerMin\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "# make deterministic\n",
    "from data_utils import \\\n",
    "    viz_current_frame_and_store_fk_info_include_fixed, \\\n",
    "    loss_angle, loss_j_pos, loss_root_dist_pos, loss_max_jerk, loss_root_jerk, our_pose_2_bullet_format\n",
    "from render_funcs import init_viz, COLOR_OURS, update_height_field_pb, set_color, COLOR_GT\n",
    "from learning_utils import set_seed\n",
    "import constants as cst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "turkish-calvin",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(1)\n",
    "np.set_printoptions(threshold=10_000, precision=10)\n",
    "torch.set_printoptions(threshold=10_000, precision=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "clean-quantum",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Run our model and related works models')\n",
    "parser.add_argument('--ours_path_name_kin', type=str, default=\"model-kin-amass-4-knee-v2.pt\",\n",
    "                    help='')\n",
    "parser.add_argument('--name_contains', type=str, default='',\n",
    "                    help='Please use \"\" to be able to pass multiple search keys split by whitespaces')\n",
    "parser.add_argument('--test_len', type=int, default=600,\n",
    "                    help='')\n",
    "parser.add_argument('--render', action='store_true',\n",
    "                    help='')\n",
    "parser.add_argument('--compare_gt', action='store_true',\n",
    "                    help='')\n",
    "parser.add_argument('--seed', type=int, default=42,\n",
    "                    help='')\n",
    "parser.add_argument('--five_sbp', action='store_true',\n",
    "                    help='')\n",
    "parser.add_argument('--with_acc_sum', action='store_true',\n",
    "                    help='')\n",
    "parser.add_argument('--viz_terrain', action='store_true',\n",
    "                    help='')\n",
    "parser.add_argument('--data_version_tag', type=str, default=None,\n",
    "                    help='')\n",
    "# parser.add_argument('--save_c', action='store_true',\n",
    "#                     help='')                # for the DIP-IMU set which has C info\n",
    "# args = parser.parse_args()\n",
    "\n",
    "MODEL_NAME=\"model-without-dip9and10\"\n",
    "MODEL_NAME_WGT=f\"output/{MODEL_NAME}.pt\"\n",
    "\n",
    "args = parser.parse_args([\n",
    "    \"--name_contains\", \"dipimu_s_09 dipimu_s_10\",\n",
    "    \"--ours_path_name_kin\", MODEL_NAME_WGT,\n",
    "    \"--with_acc_sum\",  \n",
    "    \"--test_len\", \"30000\",\n",
    "    \"--compare_gt\", \n",
    "    \"--seed\", \"42\",\n",
    "    \"--five_sbp\",\n",
    "    \"--data_version_tag\", \"v1\"\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "operational-credits",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(args.seed)\n",
    "\n",
    "TEST_LEN = args.test_len\n",
    "RENDER = args.render\n",
    "MAX_TEST_MOTION_PRE_CAT = 50        # make testing faster\n",
    "# if args.save_c:\n",
    "#     MAX_TEST_MOTION_PRE_CAT = 50000\n",
    "# else:\n",
    "#     MAX_TEST_MOTION_PRE_CAT = 50\n",
    "USE_5_SBP = args.five_sbp\n",
    "WITH_ACC_SUM = args.with_acc_sum\n",
    "\n",
    "MAP_BOUND = cst.MAP_BOUND * 2.0     # some motions are in large range\n",
    "GRID_NUM = int(MAP_BOUND/cst.GRID_SIZE) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "excellent-oliver",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ours_wrapper_with_c_rt(imu, s_gt, model_name, char) -> (np.ndarray, np.ndarray):\n",
    "    def load_model(name):\n",
    "        from simple_transformer_with_state import TF_RNN_Past_State\n",
    "        input_channels_imu = 6 * (9 + 3)\n",
    "        if USE_5_SBP:\n",
    "            output_channels = 18 * 6 + 3 + 20\n",
    "        else:\n",
    "            output_channels = 18 * 6 + 3 + 8\n",
    "\n",
    "        model = TF_RNN_Past_State(\n",
    "            input_channels_imu, output_channels,\n",
    "            rnn_hid_size=512,\n",
    "            tf_hid_size=1024, tf_in_dim=256,\n",
    "            n_heads=16, tf_layers=4,\n",
    "            dropout=0.0, in_dropout=0.0,\n",
    "            past_state_dropout=0.8,\n",
    "            with_acc_sum=WITH_ACC_SUM\n",
    "        )\n",
    "        model.load_state_dict(torch.load(name))\n",
    "        model = model.cuda()\n",
    "        # model.eval()\n",
    "        return model\n",
    "\n",
    "    m = load_model(model_name)\n",
    "\n",
    "    # ours_out, c_out, viz_locs_out = test_run_ours_gpt_v4_with_c_rt(char, s_gt, imu, m, 40)\n",
    "    ours_out, c_out, viz_locs_out = test_run_ours_gpt_v4_with_c_rt_minimal(char, s_gt, imu, m, 40)\n",
    "\n",
    "    return ours_out, c_out, viz_locs_out\n",
    "\n",
    "\n",
    "def test_run_ours_gpt_v4_with_c_rt_minimal(\n",
    "        char: SimAgent,\n",
    "        s_gt: np.array,\n",
    "        imu: np.array,\n",
    "        m: nn.Module,\n",
    "        max_win_len: int\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "\n",
    "    # use real time runner with offline data\n",
    "    rt_runner = RTRunnerMin(\n",
    "        char, m, max_win_len, s_gt[0],\n",
    "        with_acc_sum=WITH_ACC_SUM,\n",
    "    )\n",
    "\n",
    "    m_len = imu.shape[0]\n",
    "    s_traj_pred = np.zeros((m_len, cst.n_dofs * 2))\n",
    "    s_traj_pred[0] = s_gt[0]\n",
    "\n",
    "    c_traj_pred = np.zeros((m_len, rt_runner.n_sbps * 4))\n",
    "    viz_locs_seq = [np.ones((rt_runner.n_sbps, 3)) * 100.0]\n",
    "\n",
    "    for t in range(0, m_len-1):\n",
    "        res = rt_runner.step(imu[t, :], s_traj_pred[t, :3])\n",
    "\n",
    "        s_traj_pred[t + 1, :] = res['qdq']\n",
    "        c_traj_pred[t + 1, :] = res['ct']\n",
    "\n",
    "        viz_locs = res['viz_locs']\n",
    "        for sbp_i in range(viz_locs.shape[0]):\n",
    "            viz_point(viz_locs[sbp_i, :], sbp_i)\n",
    "        viz_locs_seq.append(viz_locs)\n",
    "\n",
    "        if RENDER:\n",
    "            time.sleep(1. / 180)\n",
    "\n",
    "    # throw away first \"trim\" predictions (our algorithm gives dummy values)... append dummy value in the end.\n",
    "    viz_locs_seq = np.array(viz_locs_seq)\n",
    "    assert len(viz_locs_seq) == len(s_traj_pred)\n",
    "\n",
    "    # +2 because post-processing moving average filter effectively introduce a bit more delay\n",
    "    trim = rt_runner.IMU_n_smooth + 2\n",
    "    s_traj_pred[0:-trim, :] = s_traj_pred[trim:, :]\n",
    "    s_traj_pred[-trim:, :] = s_traj_pred[-trim-1, :]\n",
    "    viz_locs_seq[0:-trim, :, :] = viz_locs_seq[trim:, :, :]\n",
    "    viz_locs_seq[-trim:, :, :] = viz_locs_seq[-trim-1, :, :]\n",
    "\n",
    "    return s_traj_pred, c_traj_pred, viz_locs_seq\n",
    "\n",
    "\n",
    "def test_run_ours_gpt_v4_with_c_rt(\n",
    "        char: SimAgent,\n",
    "        s_gt: np.array,\n",
    "        imu: np.array,\n",
    "        m: nn.Module,\n",
    "        max_win_len: int\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "\n",
    "    global h_id, h_b_id\n",
    "\n",
    "    # use real time runner with offline data\n",
    "    rt_runner = RTRunner(\n",
    "        char, m, max_win_len, s_gt[0],\n",
    "        map_bound=MAP_BOUND,\n",
    "        grid_size=cst.GRID_SIZE,\n",
    "        play_back_gt=False,\n",
    "        five_sbp=USE_5_SBP,\n",
    "        with_acc_sum=WITH_ACC_SUM,\n",
    "        multi_sbp_terrain_and_correction=False\n",
    "    )\n",
    "\n",
    "    m_len = imu.shape[0]\n",
    "    s_traj_pred = np.zeros((m_len, cst.n_dofs * 2))\n",
    "    c_traj_pred = np.zeros((m_len, rt_runner.n_sbps * 4))\n",
    "    s_traj_pred[0] = s_gt[0]\n",
    "\n",
    "    viz_locs_seq = [np.ones((rt_runner.n_sbps, 3)) * 100.0]\n",
    "\n",
    "    for t in range(0, m_len-1):\n",
    "        res = rt_runner.step(imu[t, :], s_traj_pred[t, :3], t=t)\n",
    "\n",
    "        s_traj_pred[t + 1, :] = res['qdq']\n",
    "        c_traj_pred[t + 1, :] = res['ct']\n",
    "\n",
    "        viz_locs = res['viz_locs']\n",
    "        for sbp_i in range(viz_locs.shape[0]):\n",
    "            viz_point(viz_locs[sbp_i, :], sbp_i)\n",
    "\n",
    "        viz_locs_seq.append(viz_locs)\n",
    "\n",
    "        if t % 15 == 0 and h_id is not None:\n",
    "            # TODO: double for loop...\n",
    "            for ii in range(init_grid_np.shape[0]):\n",
    "                for jj in range(init_grid_np.shape[1]):\n",
    "                    init_grid_list[jj*init_grid_np.shape[0]+ii] = \\\n",
    "                        rt_runner.region_height_list[rt_runner.height_region_map[ii, jj]]\n",
    "            h_id, h_b_id = update_height_field_pb(\n",
    "                pb_client,\n",
    "                h_data=init_grid_list,\n",
    "                scale=cst.GRID_SIZE,\n",
    "                terrainShape=h_id,\n",
    "                terrain=h_b_id\n",
    "            )\n",
    "\n",
    "        if RENDER:\n",
    "            time.sleep(1. / 180)\n",
    "\n",
    "    # throw away first \"trim\" predictions (our algorithm gives dummy values)... append dummy value in the end.\n",
    "    viz_locs_seq = np.array(viz_locs_seq)\n",
    "\n",
    "    # +2 because post-processing moving average filter effectively introduce a bit more delay\n",
    "    trim = rt_runner.IMU_n_smooth + 2\n",
    "    s_traj_pred[0:-trim, :] = s_traj_pred[trim:, :]\n",
    "    s_traj_pred[-trim:, :] = s_traj_pred[-trim-1, :]\n",
    "    viz_locs_seq[0:-trim, :, :] = viz_locs_seq[trim:, :, :]\n",
    "    viz_locs_seq[-trim:, :, :] = viz_locs_seq[-trim-1, :, :]\n",
    "\n",
    "    return s_traj_pred, c_traj_pred, viz_locs_seq\n",
    "\n",
    "\n",
    "def viz_2_trajs_and_return_fk_records_with_sbp(\n",
    "        char1: SimAgent,\n",
    "        char2: SimAgent,\n",
    "        traj1: np.ndarray,\n",
    "        traj2: np.ndarray,\n",
    "        start_t: int,\n",
    "        end_t: int,\n",
    "        gui: bool,\n",
    "        seq_c_viz: Union[np.ndarray, None],\n",
    ") -> (np.ndarray, np.ndarray, np.ndarray, np.ndarray):\n",
    "\n",
    "    m_len = len(traj1)      # use first length if mismatch\n",
    "\n",
    "    pq_g_1_s = []\n",
    "    pq_g_2_s = []\n",
    "\n",
    "    for t in range(start_t, m_len-end_t):\n",
    "\n",
    "        pq_g_2 = viz_current_frame_and_store_fk_info_include_fixed(char2, traj2[t])\n",
    "        pq_g_1 = viz_current_frame_and_store_fk_info_include_fixed(char1, traj1[t])   # GT in grey\n",
    "\n",
    "        pq_g_1_s.append(pq_g_1)\n",
    "        pq_g_2_s.append(pq_g_2)\n",
    "\n",
    "        if seq_c_viz is not None:\n",
    "            cur_c_viz = seq_c_viz[t, :, :]\n",
    "            for sbp_i in range(cur_c_viz.shape[0]):\n",
    "                viz_point(cur_c_viz[sbp_i, :], sbp_i)\n",
    "\n",
    "        if gui:\n",
    "            time.sleep(1. / 180)\n",
    "\n",
    "    return traj1[start_t: m_len-end_t], traj2[start_t: m_len-end_t], np.array(pq_g_1_s), np.array(pq_g_2_s)\n",
    "\n",
    "\n",
    "def post_processing_our_model(\n",
    "        char: SimAgent,\n",
    "        ours_out: np.ndarray) -> np.ndarray:\n",
    "    poses_post = []\n",
    "    for pose in ours_out:\n",
    "        pose_post = our_pose_2_bullet_format(char, pose)\n",
    "        poses_post.append(pose_post.tolist())\n",
    "    poses_post = np.array(poses_post)\n",
    "\n",
    "    return poses_post\n",
    "\n",
    "\n",
    "def viz_point(x, ind):\n",
    "    pb_client.resetBasePositionAndOrientation(\n",
    "        VIDs[ind],\n",
    "        x,\n",
    "        [0., 0, 0, 1]\n",
    "    )\n",
    "\n",
    "\n",
    "def get_all_testing_filenames(name_contains_list):\n",
    "    file_paths = []\n",
    "    for src_dir in imu_readings_dirs_OUR_format:\n",
    "        src_dir = os.path.join(\"data\", src_dir)\n",
    "        # list_dirs = [x[0] for x in os.walk(src_dir)]\n",
    "        # for d in list_dirs:\n",
    "        with os.scandir(src_dir) as it:\n",
    "            for entry in it:\n",
    "                n = entry.name\n",
    "                if n.endswith('pkl'):\n",
    "                    f_path = os.path.join(src_dir, n)\n",
    "                    for name_contains in name_contains_list:\n",
    "                        if re.search(name_contains, f_path, re.IGNORECASE):\n",
    "                            file_paths.append(f_path)\n",
    "\n",
    "                            break\n",
    "                        # break to here\n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adequate-canal",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    main\n",
    "\"\"\"\n",
    "\n",
    "imu_readings_dirs_OUR_format = [\n",
    "    \"syn_AMASS_CMU_v0\", \"syn_Eyes_Japan_Dataset_v0\",\n",
    "    \"syn_KIT_v0\", \"syn_HUMAN4D_v0\",\n",
    "    \"syn_ACCAD_v0\", \"syn_DFaust_67_v0\", \"syn_HumanEva_v0\", \"syn_MPI_Limits_v0\",\n",
    "    \"syn_MPI_mosh_v0\", \"syn_SFU_v0\", \"syn_Transitions_mocap_v0\",\n",
    "    \"preprocessed_DIP_IMU_v0\", \"preprocessed_TotalCapture_v0\", \"syn_TotalCapture_v0\",\n",
    "    \"syn_DanceDB_v0\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "regional-laundry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dipimu_s_09', 'dipimu_s_10']\n",
      "19\n",
      "['data/preprocessed_DIP_IMU_v1/dipimu_s_09_02_a.pkl', 'data/preprocessed_DIP_IMU_v1/dipimu_s_10_02.pkl', 'data/preprocessed_DIP_IMU_v1/dipimu_s_10_03_a.pkl', 'data/preprocessed_DIP_IMU_v1/dipimu_s_09_03_a.pkl', 'data/preprocessed_DIP_IMU_v1/dipimu_s_09_01_c.pkl', 'data/preprocessed_DIP_IMU_v1/dipimu_s_10_03_b.pkl', 'data/preprocessed_DIP_IMU_v1/dipimu_s_10_05.pkl', 'data/preprocessed_DIP_IMU_v1/dipimu_s_09_01_b.pkl', 'data/preprocessed_DIP_IMU_v1/dipimu_s_10_04_b.pkl', 'data/preprocessed_DIP_IMU_v1/dipimu_s_10_01_c.pkl', 'data/preprocessed_DIP_IMU_v1/dipimu_s_09_03_b.pkl', 'data/preprocessed_DIP_IMU_v1/dipimu_s_10_01_a.pkl', 'data/preprocessed_DIP_IMU_v1/dipimu_s_10_04_a.pkl', 'data/preprocessed_DIP_IMU_v1/dipimu_s_10_04_c.pkl', 'data/preprocessed_DIP_IMU_v1/dipimu_s_09_02_b.pkl', 'data/preprocessed_DIP_IMU_v1/dipimu_s_10_01_b.pkl', 'data/preprocessed_DIP_IMU_v1/dipimu_s_09_01_a.pkl', 'data/preprocessed_DIP_IMU_v1/dipimu_s_09_04.pkl', 'data/preprocessed_DIP_IMU_v1/dipimu_s_09_05.pkl']\n"
     ]
    }
   ],
   "source": [
    "if args.data_version_tag is not None:\n",
    "    imu_readings_dirs_OUR_format = [ name.replace(\"v0\", args.data_version_tag) for name in imu_readings_dirs_OUR_format ]\n",
    "\n",
    "# if args.save_c:\n",
    "#     try:\n",
    "#         os.makedirs(\"../release/data/preprocessed_DIP_IMU_v0_c\")    # store c here\n",
    "#     except FileExistsError:\n",
    "#         print(\"warning: path existed\")\n",
    "#     except OSError:\n",
    "#         exit()\n",
    "\n",
    "''' Load Character Info Moudle '''\n",
    "spec = importlib.util.spec_from_file_location(\n",
    "    \"char_info\", \"amass_char_info.py\")\n",
    "char_info = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(char_info)\n",
    "\n",
    "name_contains_l = args.name_contains.split()\n",
    "print(name_contains_l)\n",
    "test_files = get_all_testing_filenames(name_contains_l)\n",
    "print(len(test_files))\n",
    "if len(test_files) > MAX_TEST_MOTION_PRE_CAT:\n",
    "    test_files = random.sample(test_files, MAX_TEST_MOTION_PRE_CAT)\n",
    "print(test_files)\n",
    "\n",
    "color = COLOR_OURS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "spatial-keyboard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,\n",
       " odict_keys(['root', 'lhip', 'lknee', 'lankle', 'rhip', 'rknee', 'rankle', 'lowerback', 'upperback', 'chest', 'lowerneck', 'upperneck', 'lclavicle', 'lshoulder', 'lelbow', 'lwrist', 'rclavicle', 'rshoulder', 'relbow', 'rwrist']))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SMPL : 23 joints (22 joint rotations + 1 root xyz)\n",
    "# -> 20 joints (exclude toes, because this simulation charactor model doesn't have toes)\n",
    "len(char_info.joint_idx), char_info.joint_idx.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "blessed-slovenia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimAgent] Creating an agent... data/amass.urdf\n",
      "[SimAgent] Creating an agent... data/amass.urdf\n"
     ]
    }
   ],
   "source": [
    "# TODO: really odd, need to be huge for pybullet to work (say. 10.0)\n",
    "init_grid_np = np.random.uniform(-10.0, 10.0, (GRID_NUM, GRID_NUM))\n",
    "init_grid_list = list(init_grid_np.flatten())\n",
    "\n",
    "pb_client, c1, c2, VIDs, h_id, h_b_id = init_viz(char_info,\n",
    "                                                 init_grid_list,\n",
    "                                                 hmap_scale=cst.GRID_SIZE,\n",
    "                                                 gui=RENDER,\n",
    "                                                 compare_gt=args.compare_gt,\n",
    "                                                 color=color,\n",
    "                                                 viz_h_map=args.viz_terrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "floppy-cholesterol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/preprocessed_DIP_IMU_v1/dipimu_s_09_02_a.pkl\n",
      "model with acc sum\n",
      "number of parameters: %e 3677315\n"
     ]
    }
   ],
   "source": [
    "gt_list = []\n",
    "ours_list = []\n",
    "ours_c_list = []\n",
    "ours_c_viz_list = []\n",
    "tp_list = []\n",
    "dip_list = []\n",
    "test_files_included = []\n",
    "for f in test_files:\n",
    "\n",
    "    if not (os.path.exists(f)):\n",
    "        print(\"ignored \", f)\n",
    "        continue\n",
    "\n",
    "    data = pickle.load(open(f, \"rb\"))\n",
    "    X = data['imu']\n",
    "    Y = data['nimble_qdq']\n",
    "\n",
    "    # exclude too short trajs\n",
    "    if Y.shape[0] < 2.5 / cst.DT:\n",
    "        continue\n",
    "\n",
    "    # to make all motion equal in stat compute, and run faster\n",
    "    if Y.shape[0] > TEST_LEN:\n",
    "        rand_start = random.randrange(0, Y.shape[0] - TEST_LEN)\n",
    "        start = rand_start\n",
    "        end = rand_start + TEST_LEN\n",
    "    else:\n",
    "        start = 0\n",
    "        end = Y.shape[0]\n",
    "    X = X[start: end, :]\n",
    "    Y = Y[start: end, :]\n",
    "\n",
    "    # for clearer visualization, amass data not calibrated well wrt floor\n",
    "    # translation errors are computed from displacement not absolute Y\n",
    "    Y[:, 2] += 0.05       # move motion root 5 cm up\n",
    "\n",
    "    # print(X.shape)\n",
    "    # print(Y.shape)\n",
    "    # print(start)\n",
    "    # print(end)\n",
    "    gt_list.append(Y)\n",
    "    test_files_included.append(f)\n",
    "    print(f)\n",
    "\n",
    "    ours, C, ours_c_viz = run_ours_wrapper_with_c_rt(X, Y, args.ours_path_name_kin, c1)\n",
    "    ours_list.append(ours)\n",
    "    ours_c_viz_list.append(ours_c_viz)\n",
    "\n",
    "    # if args.save_c:\n",
    "    #     save_name = f.replace(\"v0\", \"v0_c\")\n",
    "    #     assert \"dipimu\" in f\n",
    "    #     with open(save_name, \"wb\") as handle:\n",
    "    #         assert len(X) == len(C)\n",
    "    #         print(C.shape)\n",
    "    #         pickle.dump(\n",
    "    #             {\"constrs\": C},\n",
    "    #             handle,\n",
    "    #             protocol=pickle.HIGHEST_PROTOCOL\n",
    "    #         )\n",
    "    #     print(\"saved\", save_name)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "wrapped-shanghai",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2766, 72), (2766, 114))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# s_traj_pred, c_traj_pred, viz_locs_seq = test_run_ours_gpt_v4_with_c_rt_minimal(...)\n",
    "\n",
    "\n",
    "# X : imu R^{12*6} = {(6:rotation + 3:acc_raw + 3:acc_filtered) * 6:IMUs}\n",
    "\n",
    "\n",
    "# Y : (xyz, v_xyz) R^{57*2}={(20-1):joints *3 *2:(xyz, v_xyz)}\n",
    "#    \"qdq\" = {q, dq} <- get_raw_motion_info_nimble_q_dummy_dq(...) : https://github.com/jyf588/transformer-inertial-poser/blob/adef2489c927413228ed4137c8fc58e74b58fa11/data_utils.py#L103\n",
    "\n",
    "# https://github.com/jyf588/transformer-inertial-poser/blob/adef2489c927413228ed4137c8fc58e74b58fa11/data_utils.py#L152\n",
    "#         cur_info = p.tolist() + conversions.Q2A(Q).tolist() + j_q_filtered + \\  # (1) + (1) + (1): position (xyz, rotation_xyz, omega:rotation_velocity but not used in this method)\n",
    "#                    v.tolist() + w.tolist() + j_dq_filtered                      # (1) + (1) + (1): velocity (xyz, rotation_xyz, omega:rotation_velocity but not used in this method)\n",
    "\n",
    "# https://github.com/jyf588/transformer-inertial-poser/blob/adef2489c927413228ed4137c8fc58e74b58fa11/data_utils.py#L159\n",
    "#         raw_info.shape[1] == ((n_j - 2) * 3 + 3 + 3) * 2                        # bvh : excluded root? or bones?\n",
    "\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "national-friendly",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_j = len(char_info.joint_idx) - 1\n",
    "\n",
    "t = 50\n",
    "\n",
    "p,   rot, jq = Y[t][  0:     n_j], Y[t][  n_j: 2*n_j], Y[t][2*n_j: 3*n_j] \n",
    "v, v_rot, jq = Y[t][3*n_j: 4*n_j], Y[t][4*n_j: 5*n_j], Y[t][5*n_j: 6*n_j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "israeli-syndicate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 114, (2766, 114))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_j, n_j*3*2, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "amino-bosnia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.0000000000e+00,  0.0000000000e+00,  1.0000000000e+00,\n",
       "         1.2026493846e+00,  1.1896968088e+00,  1.2280366796e+00,\n",
       "         2.2138730302e-02, -8.0699120000e-02, -6.2238155678e-02,\n",
       "         1.1058685927e-03,  1.2425061766e-01,  3.6405972939e-03,\n",
       "        -1.7372373470e-02,  3.9497703230e-03, -9.4995158459e-03,\n",
       "        -3.0942233726e-02,  2.8092124635e-02,  4.3664312617e-03,\n",
       "         4.5304625291e-04]),\n",
       " array([-6.0254008695e-02,  3.7774364722e-04,  4.5413941933e-02,\n",
       "        -1.0353254971e-02, -8.7695608120e-04,  5.9420230920e-02,\n",
       "        -2.6895332766e-03, -3.5781063244e-01, -1.4022067236e-01,\n",
       "        -4.0529519310e-02, -1.1163524556e+00,  1.1251337152e-01,\n",
       "        -1.3060419515e-01, -1.2833978138e-01,  2.6065982226e-02,\n",
       "         1.3510166233e-02, -2.7034303884e-02,  2.5670629608e-02,\n",
       "        -1.5341262707e-02]),\n",
       " array([ 0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0., -0.,  0.,  0.,  0.,  0.]),\n",
       " array([ 0.          ,  0.          ,  0.          ,  0.0040361452,\n",
       "        -0.0024344627, -0.0047054379,  0.          , -0.          ,\n",
       "        -0.          ,  0.          ,  0.          ,  0.          ,\n",
       "        -0.          ,  0.          , -0.          , -0.          ,\n",
       "         0.          ,  0.          ,  0.          ]),\n",
       " array([-0.,  0.,  0., -0., -0.,  0., -0., -0., -0., -0., -0.,  0., -0.,\n",
       "        -0.,  0.,  0., -0.,  0., -0.]),\n",
       " array([ 0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0., -0.,  0.,  0.,  0.,  0.]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p,   rot, jq, \\\n",
    "v, v_rot, jq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "purple-sussex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2766, 114), (2766, 20), (2766, 5, 3))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# s_traj_pred, c_traj_pred, viz_locs_seq = test_run_ours_gpt_v4_with_c_rt_minimal(...)\n",
    "\n",
    "# s_traj_pred = Y : root_xyz R^{57*2}={(20-1)joints *3 *2}, \"qdq\" = {q, dq}\n",
    "# c_traj_pred : SBP_t R^{5*4}, \"ct\" = {b_t, r_t}\n",
    "# viz_locs_seq : xyz(SBP_t) R^{5*3}, \"viz_locs\" = {xyz_t}\n",
    "\n",
    "ours.shape, C.shape, ours_c_viz.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-english",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
